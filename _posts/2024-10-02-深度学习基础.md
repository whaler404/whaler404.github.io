---
layout: post
title:  深度学习基础
# subtitle: 
date:   2024-10-01
author: whaler404
header-img: img/post-bg-playphone.jpg
categories: post
catalog: true
tags:
    - dl
---

# 书籍
[动手学深度学习](http://zh.gluon.ai/)<br>
[动手学深度学习v2](https://zh-v2.d2l.ai/)<br>
[深入浅出PyTorch](https://datawhalechina.github.io/thorough-pytorch/index.html)<br>
[eat_pytorch_in_20_days](https://jackiexiao.github.io/eat_pytorch_in_20_days/)<br>
[chenyuntc/pytorch-book](https://github.com/chenyuntc/pytorch-book/tree/master)<br>

# 文档
[AutoDL 帮助文档](https://www.autodl.com/docs/gpu/)<br>
[Pytorch tutorial](https://pytorch.org/tutorials/)<br>
[Pytorch Doc](https://pytorch.org/docs/stable/index.html)<br>


# 博客
[廖雪峰的 Python 教程](https://liaoxuefeng.com/books/python/introduction/index.html)<br>
[labml side-by-side notes](https://nn.labml.ai/)<br>
[citisy 的炼丹房](https://www.citisy.site/)<br>
[llm_interview_note](https://dongnian.icu/llm_interview_note/#/)<br>
[GiantPandaCV CV 学术和工程方面的干货](http://giantpandacv.com/)<br>

# 项目
[labml.ai Deep Learning Paper Implementations](https://github.com/labmlai/annotated_deep_learning_paper_implementations)<br>
[Awesome-pytorch-list](https://github.com/bharathgs/Awesome-pytorch-list)<br>
[pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial)<br>
[torch-template-for-deep-learning](https://github.com/ZhugeKongan/torch-template-for-deep-learning)<br>
[pytorch-template-by-victoresque](https://github.com/victoresque/pytorch-template)<br>
[pytorch-template-by-songquanpeng](https://github.com/songquanpeng/pytorch-template)<br>

[wonderful-prompts](https://github.com/langgptai/wonderful-prompts)

# 文章

## GPU
[GPU 利用率是一个具有误导性的指标|nvidia-smi不能反映真正的GPU性能](https://zhuanlan.zhihu.com/p/717605060)<br>
[GPU 架构与 CUDA 关系](https://zhuanlan.zhihu.com/p/697746975)<br>
[显卡、显卡驱动、cuda 之间的关系是什么？](https://www.zhihu.com/question/59184480/answer/3592458636)<br>

## Pytorch
[PyTorch：一文了解pytorch模块结构](https://zhuanlan.zhihu.com/p/710535197)<br>
[pytorch框架的详细介绍与应用详解](https://zhuanlan.zhihu.com/p/720035960)<br>
[如何提高自己的代码能力以达到熟练使用pytorch?](https://www.zhihu.com/question/352525266/answer/3395318281)<br>
[PyTorch半精度训练/混合精度训练](https://zhuanlan.zhihu.com/p/678116738)<br>

[一个Tensor的生命历程(Pytorch版)](https://oldpan.me/archives/life-of-a-tensor)<br>
[PyTorch 内部机制解析：如何通过 PyTorch 实现 Tensor](https://www.pytorchtutorial.com/how-to-implement-tensor-in-pytorch/)<br>
[python中的包](https://blog.csdn.net/m0_53271604/article/details/141962166)<br>
[PyTorch中的pyi档案生成机制](https://blog.csdn.net/keineahnung2345/article/details/133075986)<br>

[torch的广播机制(broadcast mechanism)](https://zhuanlan.zhihu.com/p/86997775)<br>
[【Pytorch】对比clone、detach以及copy_等张量复制操作](https://blog.csdn.net/guofei_fly/article/details/104486708)<br>
[【Pytorch】区分detach()和torch.no_grad()](https://blog.csdn.net/yzy_1996/article/details/114790404)<br>
[20天吃掉那只Pytorch————2-3,动态计算图](https://jackiexiao.github.io/eat_pytorch_in_20_days/2.%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/2-3%2C%E5%8A%A8%E6%80%81%E8%AE%A1%E7%AE%97%E5%9B%BE/)<br>

## Trick
[大家写深度学习代码的时候，都是怎么检查代码错没错的？](https://www.zhihu.com/question/545109120/answer/2752651116)<br>
[深度学习调参有哪些技巧？](https://www.zhihu.com/question/25097993/answer/3415424048)<br>
[为什么用pytorch cuda，明明显存很够用，却报错out of memory？](https://www.zhihu.com/question/529993552/answer/3370717327)<br>

## 网络架构
[存在错误标注的伪标签为什么会帮助训练出更好的模型?](https://www.zhihu.com/question/563144316/answer/2773482635)<br>
[深度学习中Dropout原理解析](https://zhuanlan.zhihu.com/p/38200980)<br>
[为什么残差连接的网络结构更容易学习？](https://www.zhihu.com/question/306135761/answer/2491142607)<br>
[为什么 Bert 的三个 Embedding 可以进行相加？](https://www.zhihu.com/question/374835153/answer/1042845667)<br>
[Transformer模型详解（图解最完整版）](https://zhuanlan.zhihu.com/p/338817680)<br>
[一文读懂KVCache](https://zhuanlan.zhihu.com/p/686183300)<br>

## Python
[原来 Python 也有重载？](https://blog.csdn.net/qq_35491275/article/details/124559459)<br>
[pyi文件是干嘛的？（一文读懂Python的存根文件和类型检查）](https://www.cnblogs.com/chester-cs/p/14000921.html)<br>
[python \_\_init\_\_.py 文件的用法](https://muyuuuu.github.io/2021/07/11/python-init-file/)<br>
[浅析什么是HOOK](https://www.cnblogs.com/ArsenalfanInECNU/p/12871887.html)<br>


如何获取 Python 模块的路径？`torch.__file__`

# Pytorch 学习笔记

> 更多 pytorch 模块的功能介绍见 [Pytorch 官方文档](https://pytorch.org/docs/stable/index.html) 或使用 `help()` 函数查看

[Tensor](https://pytorch.org/docs/2.4/tensors.html) 的[操作分类](https://pytorch.org/docs/2.4/torch.html)：
- 结构操作：
    1. 创建张量：tensor、arange、linspace、zeros、zeros_like、ones、ones_like、fill、manual_seed、rand、randn、normal、randperm、eye、diag
    2. 索引切片：`tensor[0,1,2:4,:4,::2]`、narrow、index_select、take、masked_select、where、index_fill、masked_fill、scatter、gather
    3. 维度变换：view、reshape、squeeze、unsqueeze、transpose、permute、flatten、expand、repeat
    4. 合并分割：stack、cat、split、chunk、unbind

    **Tensor View 机制**：[视图张量](https://pytorch.org/docs/2.4/tensor_view.html)与其基本张量共享相同的基础数据，支持进行快速且内存高效的重塑、切片和逐元素操作。
    
- 运算操作：
    1. 标量运算：neg、add、sub、mul、div、floor_divide、fmod、remainer、pow、sqrt、abs、exp、log、sigmoid、ge、le、eq、floor、ceil、max、round、trunc、min、argmax、argmin、clamp
    2. 向量运算：sum、mean、prod、var、std、median、cum、sort、topk
    3. [矩阵运算](https://pytorch.org/docs/2.4/linalg.html)：matmul、mm、bmm、t、inverse、trace、norm、det、eig、qr、svd、tensordot、einsum
    4. 广播运算：broadcast_tensors

[`torch.nn`](https://pytorch.org/docs/2.4/nn.html) 模块：
- 一般将参数用 [`nn.Parameter`](https://pytorch.org/docs/2.4/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter) 来表示，并且用 `nn.Module` 来管理其结构下的所有参数。
- `nn.functional` 有各种功能组件的函数实现，但为了便于对参数进行管理，一般通过继承 `nn.Module` 转换成为类的实现形式，并直接封装在 nn 模块下
- 支持多种模型容器和模型层

[`torch.util.data`](https://pytorch.org/docs/2.4/data.html#) 模块：Dataset 定义了数据集的内容，DataLoader 定义了按 batch 加载数据集的方法